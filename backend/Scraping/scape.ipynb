{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001d4dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Restaurant Scrape\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "\n",
    "API_KEY = 'AIzaSyABr7ljK68VEpnzBFayW4tS4H6lG1bHWWg'  # Replace with your actual key\n",
    "location = '41.476687,-81.658110'  # Cleveland, OH\n",
    "radius = 60000  # meters\n",
    "\n",
    "# Cuisine search terms\n",
    "cuisine_keywords = [\n",
    "    'Restaurant', 'Chinese', 'Italian', 'American', 'Vietnamese', 'Barbeque',\n",
    "    'Mediterranean', 'Mexican', 'Guatemalan', 'Lebanese', 'Japanese', 'Indian',\n",
    "    'New American', 'Grill', 'Cajun', 'Middle Eastern', 'Soul', 'Hamburger',\n",
    "    'Sandwich', 'Fast Food', 'Pub', 'Pizza', 'Steak', 'Chicken', 'Asian',\n",
    "    'Fine Dining', 'Vegetarian', 'Vegan', 'Brewpub', 'Pho', 'French', 'Bakery'\n",
    "]\n",
    "\n",
    "# Map price_level to readable format\n",
    "price_map = {0: \"Free\", 1: \"$\", 2: \"$$\", 3: \"$$$\", 4: \"$$$$\"}\n",
    "\n",
    "all_places = []\n",
    "base_url = \"https://maps.googleapis.com/maps/api/place/textsearch/json\"\n",
    "details_url = \"https://maps.googleapis.com/maps/api/place/details/json\"\n",
    "\n",
    "for keyword in cuisine_keywords:\n",
    "    print(f\"Searching for: {keyword}\")\n",
    "    params = {\n",
    "        \"query\": keyword + \" restaurant\",\n",
    "        \"location\": location,\n",
    "        \"radius\": radius,\n",
    "        \"key\": API_KEY\n",
    "    }\n",
    "\n",
    "    while True:\n",
    "        response = requests.get(base_url, params=params)\n",
    "        data = response.json()\n",
    "\n",
    "        if data.get(\"status\") != \"OK\":\n",
    "            print(\"API error:\", data.get(\"error_message\"))\n",
    "            break\n",
    "\n",
    "        for place in data.get(\"results\", []):\n",
    "            raw_price = place.get('price_level')\n",
    "            price_desc = price_map.get(raw_price, \"Unknown\")\n",
    "\n",
    "            name = place.get('name', '').lower()\n",
    "            types = [t.lower() for t in place.get('types', [])]\n",
    "\n",
    "            detected_cuisine = next(\n",
    "                (c for c in cuisine_keywords if c.lower() in name or c.lower().replace(\" \", \"_\") in types),\n",
    "                \"Not specified\"\n",
    "            )\n",
    "\n",
    "            place_id = place.get('place_id')\n",
    "\n",
    "            # Fetch details to get photos, reviews, and description\n",
    "            detail_params = {\n",
    "                \"place_id\": place_id,\n",
    "                \"fields\": \"name,formatted_address,rating,price_level,photos,reviews,user_ratings_total,types,editorial_summary\",\n",
    "                \"key\": API_KEY\n",
    "            }\n",
    "            detail_resp = requests.get(details_url, params=detail_params)\n",
    "            detail_data = detail_resp.json()\n",
    "\n",
    "            if detail_data.get(\"status\") != \"OK\":\n",
    "                print(f\"Details error for Place ID {place_id}: {detail_data.get('error_message')}\")\n",
    "                continue\n",
    "\n",
    "            result = detail_data.get('result', {})\n",
    "\n",
    "            # Extract photos into a list\n",
    "            photo_references = [\n",
    "                photo.get('photo_reference')\n",
    "                for photo in result.get('photos', [])\n",
    "                if photo.get('photo_reference')\n",
    "            ]\n",
    "\n",
    "            # Extract reviews into a list\n",
    "            review_texts = [\n",
    "                review.get('text')\n",
    "                for review in result.get('reviews', [])\n",
    "                if review.get('text')\n",
    "            ]\n",
    "\n",
    "            # Extract editorial summary (description)\n",
    "            description = result.get('editorial_summary', {}).get('overview')\n",
    "\n",
    "            all_places.append({\n",
    "                'Name': result.get('name'),\n",
    "                'Address': result.get('formatted_address'),\n",
    "                'Rating': result.get('rating'),\n",
    "                'User Ratings Total': result.get('user_ratings_total'),\n",
    "                'Place ID': place_id,\n",
    "                'Price': price_desc,\n",
    "                'Matched Type': keyword,\n",
    "                'Cuisine': detected_cuisine,\n",
    "                'Google Types': result.get('types', []),\n",
    "                'Description': description,\n",
    "                'Photos': photo_references,\n",
    "                'Reviews': review_texts\n",
    "            })\n",
    "\n",
    "        next_page_token = data.get(\"next_page_token\")\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "        time.sleep(2)\n",
    "        params[\"pagetoken\"] = next_page_token\n",
    "\n",
    "# Save to JSON\n",
    "output_path = \"/Users/stevelin/Downloads/ComboCSV/Cleveland_restaurants_with_photos_reviews.json\"\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(all_places, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Retrieved {len(all_places)} restaurants with descriptions, photos, and reviews.\")\n",
    "print(f\"Data saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649a509f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attractions Scrape\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "\n",
    "API_KEY = 'AIzaSyABr7ljK68VEpnzBFayW4tS4H6lG1bHWWg'  # Replace with your actual API key\n",
    "location = '41.495243,-81.699488'  # Cleveland, OH\n",
    "radius = 50000  # in meters\n",
    "place_types = ['museum', 'tourist_attraction', 'art_gallery', 'zoo', 'aquarium']\n",
    "\n",
    "# Price level mapping\n",
    "price_map = {0: \"Free\", 1: \"$\", 2: \"$$\", 3: \"$$$\", 4: \"$$$$\"}\n",
    "\n",
    "all_places = []\n",
    "base_url = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json\"\n",
    "details_url = \"https://maps.googleapis.com/maps/api/place/details/json\"\n",
    "\n",
    "for search_type in place_types:\n",
    "    print(f\"Searching for: {search_type}\")\n",
    "    params = {\n",
    "        \"location\": location,\n",
    "        \"radius\": radius,\n",
    "        \"type\": search_type,\n",
    "        \"key\": API_KEY\n",
    "    }\n",
    "\n",
    "    while True:\n",
    "        response = requests.get(base_url, params=params)\n",
    "        data = response.json()\n",
    "\n",
    "        if data.get(\"status\") != \"OK\":\n",
    "            print(\"API error:\", data.get(\"error_message\"))\n",
    "            break\n",
    "\n",
    "        for place in data.get(\"results\", []):\n",
    "            raw_price = place.get('price_level')\n",
    "            price_desc = price_map.get(raw_price, \"Not specified\")\n",
    "            place_id = place.get('place_id')\n",
    "\n",
    "            # Fetch detailed info\n",
    "            detail_params = {\n",
    "                \"place_id\": place_id,\n",
    "                \"fields\": \"name,formatted_address,rating,price_level,photos,reviews,user_ratings_total,types,editorial_summary\",\n",
    "                \"key\": API_KEY\n",
    "            }\n",
    "            detail_resp = requests.get(details_url, params=detail_params)\n",
    "            detail_data = detail_resp.json()\n",
    "\n",
    "            if detail_data.get(\"status\") != \"OK\":\n",
    "                print(f\"Details error for Place ID {place_id}: {detail_data.get('error_message')}\")\n",
    "                continue\n",
    "\n",
    "            result = detail_data.get('result', {})\n",
    "\n",
    "            # Get all available photo URLs\n",
    "            photo_references = [\n",
    "                photo.get('photo_reference')\n",
    "                for photo in result.get('photos', [])\n",
    "                if photo.get('photo_reference')\n",
    "            ]\n",
    "\n",
    "            # Get all available review texts\n",
    "            review_texts = [\n",
    "                review.get('text')\n",
    "                for review in result.get('reviews', [])\n",
    "                if review.get('text')\n",
    "            ]\n",
    "\n",
    "            # Get editorial description if available\n",
    "            description = result.get('editorial_summary', {}).get('overview')\n",
    "\n",
    "            all_places.append({\n",
    "                'Name': result.get('name'),\n",
    "                'Address': result.get('formatted_address'),\n",
    "                'Rating': result.get('rating'),\n",
    "                'User Ratings Total': result.get('user_ratings_total'),\n",
    "                'Place ID': place_id,\n",
    "                'Matched Type': search_type,\n",
    "                'Google Types': result.get('types', []),\n",
    "                'Price': price_desc,\n",
    "                'Description': description,\n",
    "                'Photos': photo_references,\n",
    "                'Reviews': review_texts\n",
    "            })\n",
    "\n",
    "        next_page_token = data.get(\"next_page_token\")\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "        time.sleep(2)  # Allow time for the next page token to activate\n",
    "        params[\"pagetoken\"] = next_page_token\n",
    "\n",
    "# Save to JSON\n",
    "output_path = \"/Users/stevelin/Downloads/ComboCSV/Cleveland_museums_and_attractions_with_photos_reviews.json\"\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(all_places, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Retrieved {len(all_places)} attractions with photos and reviews.\")\n",
    "print(f\"Data saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa8ab4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outdoors Scrape\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "\n",
    "API_KEY = 'AIzaSyABr7ljK68VEpnzBFayW4tS4H6lG1bHWWg'  # Replace with your actual API key\n",
    "location = '41.4993,-81.6944'  # Cleveland, OH\n",
    "radius = 20000  # meters\n",
    "place_types = ['park', 'campground', 'tourist_attraction']\n",
    "\n",
    "price_map = {0: \"Free\", 1: \"$\", 2: \"$$\", 3: \"$$$\", 4: \"$$$$\"}\n",
    "\n",
    "all_places = []\n",
    "base_url = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json\"\n",
    "details_url = \"https://maps.googleapis.com/maps/api/place/details/json\"\n",
    "\n",
    "for place_type in place_types:\n",
    "    print(f\"Searching for: {place_type}\")\n",
    "    params = {\n",
    "        \"location\": location,\n",
    "        \"radius\": radius,\n",
    "        \"type\": place_type,\n",
    "        \"key\": API_KEY\n",
    "    }\n",
    "\n",
    "    while True:\n",
    "        response = requests.get(base_url, params=params)\n",
    "        data = response.json()\n",
    "\n",
    "        if data.get(\"status\") != \"OK\":\n",
    "            print(\"API error:\", data.get(\"error_message\"))\n",
    "            break\n",
    "\n",
    "        for place in data.get(\"results\", []):\n",
    "            raw_price = place.get('price_level')\n",
    "            price_desc = price_map.get(raw_price, \"Not specified\")\n",
    "            place_id = place.get('place_id')\n",
    "\n",
    "            # Get detailed information\n",
    "            detail_params = {\n",
    "                \"place_id\": place_id,\n",
    "                \"fields\": \"name,formatted_address,rating,price_level,photos,reviews,user_ratings_total,types,editorial_summary\",\n",
    "                \"key\": API_KEY\n",
    "            }\n",
    "            detail_resp = requests.get(details_url, params=detail_params)\n",
    "            detail_data = detail_resp.json()\n",
    "\n",
    "            if detail_data.get(\"status\") != \"OK\":\n",
    "                print(f\"Details error for Place ID {place_id}: {detail_data.get('error_message')}\")\n",
    "                continue\n",
    "\n",
    "            result = detail_data.get('result', {})\n",
    "\n",
    "            # Collect all photo URLs\n",
    "            photo_references = [\n",
    "                photo.get('photo_reference')\n",
    "                for photo in result.get('photos', [])\n",
    "                if photo.get('photo_reference')\n",
    "            ]\n",
    "\n",
    "            # Collect all reviews\n",
    "            review_texts = [review.get('text') for review in result.get('reviews', []) if review.get('text')]\n",
    "\n",
    "            # Get editorial summary (description)\n",
    "            description = result.get('editorial_summary', {}).get('overview')\n",
    "\n",
    "            # Append to list\n",
    "            all_places.append({\n",
    "                'Name': result.get('name'),\n",
    "                'Address': result.get('formatted_address'),\n",
    "                'Rating': result.get('rating'),\n",
    "                'User Ratings Total': result.get('user_ratings_total'),\n",
    "                'Place ID': place_id,\n",
    "                'Matched Type': place_type,\n",
    "                'Google Types': result.get('types', []),\n",
    "                'Price': price_desc,\n",
    "                'Description': description,\n",
    "                'Photos': photo_references,\n",
    "                'Reviews': review_texts\n",
    "            })\n",
    "\n",
    "        # Handle pagination\n",
    "        next_page_token = data.get(\"next_page_token\")\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "        time.sleep(2)\n",
    "        params[\"pagetoken\"] = next_page_token\n",
    "\n",
    "# Save everything into a JSON file\n",
    "output_path = \"/Users/stevelin/Downloads/ComboCSV/Cleveland_outdoor_places_with_photos_reviews.json\"\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(all_places, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Retrieved {len(all_places)} places with photos and reviews.\")\n",
    "print(f\"Data saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625dc31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#JSON Merge\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Folder where all your JSON files are\n",
    "folder_path = \"/Users/stevelin/Downloads/ComboCSV\"\n",
    "\n",
    "# Find all JSON files in the folder\n",
    "json_files = glob.glob(os.path.join(folder_path, \"*.json\"))\n",
    "\n",
    "# Load and merge all JSONs\n",
    "all_data = []\n",
    "for file in json_files:\n",
    "    print(f\"Loading {file}...\")\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        # Optional: Add source file info\n",
    "        for record in data:\n",
    "            record['Source File'] = os.path.basename(file)\n",
    "        all_data.extend(data)\n",
    "\n",
    "# Save the merged file\n",
    "output_path = os.path.join(folder_path, \"Merged_Cleveland_Data.json\")\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(all_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Successfully merged {len(json_files)} files into {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6520988",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean File\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load your merged JSON file\n",
    "input_path = '/Users/stevelin/Downloads/ComboCSV/Merged_Cleveland_Data.json'\n",
    "with open(input_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Convert JSON list into a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Find duplicates based on 'Name' and 'Place ID'\n",
    "duplicates = df[df.duplicated(subset=['Name', 'Place ID'])]\n",
    "\n",
    "# Remove duplicates\n",
    "df_cleaned = df.drop_duplicates(subset=['Name', 'Place ID'])\n",
    "\n",
    "# Save the cleaned DataFrame back to JSON\n",
    "output_path = '/Users/stevelin/Downloads/ComboCSV/Cleaned_Merged_Cleveland_Data.json'\n",
    "df_cleaned.to_json(output_path, orient='records', indent=4, force_ascii=False)\n",
    "\n",
    "# Print summary\n",
    "print(f\"Duplicates removed: {len(duplicates)}\")\n",
    "print(f\"Cleaned file saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5305847b",
   "metadata": {},
   "source": [
    "Cleaned_Merged_Cleveland_Data.json was then manually imported into MongoDB through MongoDB Compass as trying to import through python resulted in a memory error as a result of ffi.callback() as MongoDB was unable to allocate write+execute memory. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
